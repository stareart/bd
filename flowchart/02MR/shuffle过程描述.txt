1、input:
1.1 maptask输入对象是split（分片）
1.2 block：split数量比默认1:1，可以为1:n
1.3 分片大小通过mapred-site.xml设置

2、patition
2.1 map任务完成后是一个K/V对，为了确定该K/V对交由哪个reduce处理，需要进行分区操作，默认分区方法为对Key进行hash后对reduce数量取模
2.2 将K/V值和分区结果序列化为字节数组，写入环形缓冲区（是一个字节数组）
2.3 缓冲区目的是为了减少磁盘IO

3、Spill（内存――>磁盘）
3.1 缓冲区默认最大为100MB，默认溢写阈值为80%，达到阈值启动一个单独的线程Spill
3.2 Spill锁定80MB的缓存数据进行写磁盘
3.3 溢写线程启动后，新建一个溢出文件空文件，对80MB的数据按照Key（序列化的字节）进行排序
3.4 如果设置过Combiner，将相同的Key的value进行聚合，减少到磁盘的数据量，聚合可能存在多次
3.5 如果设置过压缩，采用压缩算法对Sort和Combiner的结果进行压缩
3.6 将经过Sort、Combiner、压缩的文件写入到溢写文件中
3.7 写过程不影响map结果的输出，仅当缓存不足时阻塞缓存写入


4、merge（map端的归并）
4.1 每次Spill生成一个溢写文件，如果map的输出结果很大，会有多次这样的溢写过程，最终会生成多个溢写文件
4.2 有多个溢写文件时需要进行merge成一个文件，会将不同的溢写文件进行Group，如：{“k1”, [5, 8, 2, …]}
4.3 如果设置过Combiner，也会使用Combiner进行聚合

5、copy（拉取map的数据）
5.1 每个reduce task不断地通过RPC从JobTracker那里获取map task是否完成的信息
5.2 获取到通知后，reduce进程启动copy线程(Fetcher)，通过http方式请求map task所在TaskTracker获取输出文件，拉取数据存储到缓存

6、merge（reduce端的归并）
6.1 该部分merge有三种：1)内存到内存 2)内存到磁盘 3)磁盘到磁盘
6.2 类似map端的溢写，当缓存中的数据流达到一定阈值，启动第2种：内存merge写到磁盘
6.3 如果设置过Combiner，也会启动聚合
6.4 不断重复2)内存到磁盘
6.5 直到map输出文件都被读取结束，启动第3种:磁盘到磁盘，生成最终的文件

7、输出给reduce
7.1 不断地merge后，最后会生成一个“最终文件”（存在于内存或磁盘，默认为磁盘），提供给reduce task作为输入进行处理。